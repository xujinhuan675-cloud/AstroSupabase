/**
 * æ„å»ºæ—¶é¢„æ¸²æŸ“è„šæœ¬
 * ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†æ‰€æœ‰æ–‡ç« çš„ Markdown
 * ç±»ä¼¼ Quartz 4.0 çš„æ„å»ºæ—¶ä¼˜åŒ–ç­–ç•¥
 */

import { Worker } from 'worker_threads';
import { db } from '../src/db/client.js';
import { articles } from '../src/db/schema.js';
import { eq } from 'drizzle-orm';
import { cpus } from 'os';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

interface Article {
  id: number;
  title: string;
  slug: string;
  content: string;
}

interface WorkerResult {
  articleId: number;
  html: string;
  readingTime: string;
  success: boolean;
  error?: string;
}

// æ€§èƒ½è®¡æ—¶å™¨
class PerfTimer {
  private startTime: [number, number];
  
  constructor() {
    this.startTime = process.hrtime();
  }
  
  elapsed(): string {
    const [seconds, nanoseconds] = process.hrtime(this.startTime);
    const ms = seconds * 1000 + nanoseconds / 1000000;
    
    if (ms < 1000) {
      return `${ms.toFixed(0)}ms`;
    } else {
      return `${(ms / 1000).toFixed(2)}s`;
    }
  }
}

// å¹¶å‘å¤„ç†æ–‡ç« 
async function processArticlesInParallel(
  articles: Article[],
  concurrency: number
): Promise<Map<number, WorkerResult>> {
  const results = new Map<number, WorkerResult>();
  const workerPath = path.join(__dirname, 'markdown-worker.js');
  
  console.log(`\nğŸ”§ Creating ${concurrency} worker threads...`);
  
  // åˆ›å»º Worker æ± 
  const workers: Worker[] = [];
  for (let i = 0; i < concurrency; i++) {
    workers.push(new Worker(workerPath));
  }
  
  // ç­‰å¾…æ‰€æœ‰ Worker å°±ç»ª
  await Promise.all(
    workers.map(worker => 
      new Promise(resolve => {
        worker.once('message', (msg) => {
          if (msg.ready) resolve(true);
        });
      })
    )
  );
  
  console.log(`âœ“ Workers ready\n`);
  
  // åˆ†é…ä»»åŠ¡
  let completedCount = 0;
  const totalCount = articles.length;
  
  return new Promise((resolve, reject) => {
    let nextArticleIndex = 0;
    let activeWorkers = workers.length;
    
    const assignNextArticle = (worker: Worker) => {
      if (nextArticleIndex >= articles.length) {
        worker.terminate();
        activeWorkers--;
        
        if (activeWorkers === 0) {
          resolve(results);
        }
        return;
      }
      
      const article = articles[nextArticleIndex++];
      
      worker.postMessage({
        articleId: article.id,
        title: article.title,
        content: article.content,
        slug: article.slug,
      });
    };
    
    // ä¸ºæ¯ä¸ª Worker è®¾ç½®æ¶ˆæ¯å¤„ç†
    workers.forEach(worker => {
      worker.on('message', (result: WorkerResult) => {
        if ('ready' in result) return; // å¿½ç•¥å°±ç»ªæ¶ˆæ¯
        
        completedCount++;
        results.set(result.articleId, result);
        
        // è¿›åº¦æ˜¾ç¤º
        const percent = ((completedCount / totalCount) * 100).toFixed(1);
        process.stdout.write(`\r  Processing: ${completedCount}/${totalCount} (${percent}%)`);
        
        // åˆ†é…ä¸‹ä¸€ä¸ªä»»åŠ¡
        assignNextArticle(worker);
      });
      
      worker.on('error', (error) => {
        console.error(`\nâœ— Worker error:`, error);
        reject(error);
      });
      
      // å¼€å§‹ç¬¬ä¸€æ‰¹ä»»åŠ¡
      assignNextArticle(worker);
    });
  });
}

// æ‰¹é‡æ›´æ–°æ•°æ®åº“
async function batchUpdateDatabase(results: Map<number, WorkerResult>) {
  console.log(`\n\nğŸ’¾ Updating database...`);
  const updateTimer = new PerfTimer();
  
  let successCount = 0;
  let failCount = 0;
  
  // æ‰¹é‡æ›´æ–°ï¼ˆæ¯æ‰¹ 50 ä¸ªï¼‰
  const BATCH_SIZE = 50;
  const entries = Array.from(results.entries());
  
  for (let i = 0; i < entries.length; i += BATCH_SIZE) {
    const batch = entries.slice(i, i + BATCH_SIZE);
    
    await Promise.all(
      batch.map(async ([articleId, result]) => {
        if (result.success) {
          try {
            await db
              .update(articles)
              .set({
                htmlContent: result.html,
                readingTime: result.readingTime,
              })
              .where(eq(articles.id, articleId));
            successCount++;
          } catch (error) {
            console.error(`\n  âœ— Failed to update article ${articleId}:`, error);
            failCount++;
          }
        } else {
          failCount++;
        }
      })
    );
    
    // è¿›åº¦æ˜¾ç¤º
    const progress = Math.min(i + BATCH_SIZE, entries.length);
    process.stdout.write(`\r  Updating: ${progress}/${entries.length}`);
  }
  
  console.log(`\nâœ“ Database updated in ${updateTimer.elapsed()}`);
  console.log(`  Success: ${successCount}, Failed: ${failCount}`);
}

// ä¸»å‡½æ•°
async function main() {
  console.log('ğŸš€ Starting build-time pre-rendering...\n');
  const totalTimer = new PerfTimer();
  
  try {
    // 1. æŸ¥è¯¢æ‰€æœ‰éœ€è¦å¤„ç†çš„æ–‡ç« 
    console.log('ğŸ“š Fetching articles from database...');
    const fetchTimer = new PerfTimer();
    
    const allArticles = await db
      .select({
        id: articles.id,
        title: articles.title,
        slug: articles.slug,
        content: articles.content,
      })
      .from(articles)
      .where(eq(articles.status, 'published'));
    
    console.log(`âœ“ Fetched ${allArticles.length} articles in ${fetchTimer.elapsed()}\n`);
    
    if (allArticles.length === 0) {
      console.log('â„¹ï¸  No articles to process');
      return;
    }
    
    // 2. è®¡ç®—å¹¶å‘æ•°ï¼ˆåŸºäº CPU æ ¸å¿ƒæ•°å’Œæ–‡ç« æ•°é‡ï¼‰
    const cpuCount = cpus().length;
    const CHUNK_SIZE = 128; // ç±»ä¼¼ Quartz çš„ç­–ç•¥
    const maxConcurrency = Math.min(
      Math.max(Math.floor(allArticles.length / CHUNK_SIZE), 1),
      Math.min(cpuCount, 4) // æœ€å¤š 4 ä¸ªçº¿ç¨‹
    );
    
    console.log(`âš¡ Processing with ${maxConcurrency} thread(s) (CPU cores: ${cpuCount})\n`);
    
    // 3. å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†
    const processTimer = new PerfTimer();
    const results = await processArticlesInParallel(allArticles, maxConcurrency);
    console.log(`\nâœ“ Processed ${allArticles.length} articles in ${processTimer.elapsed()}`);
    
    // 4. æ‰¹é‡æ›´æ–°æ•°æ®åº“
    await batchUpdateDatabase(results);
    
    // 5. å®Œæˆ
    console.log(`\nâœ… Pre-rendering complete in ${totalTimer.elapsed()}`);
    console.log(`   Average: ${(parseFloat(processTimer.elapsed()) / allArticles.length).toFixed(0)}ms per article\n`);
    
    process.exit(0);
    
  } catch (error) {
    console.error('\nâŒ Pre-rendering failed:', error);
    process.exit(1);
  }
}

// è¿è¡Œ
main();

